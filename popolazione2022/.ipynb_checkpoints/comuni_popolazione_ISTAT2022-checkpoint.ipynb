{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c61fcd1-1aea-4f56-92a8-d7dcd366b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac117724-91cc-4e52-8661-de0c383c2e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-SARDEGNA.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-SICILIA.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-LOMBARDIA.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/16-Puglia_Focus-2022_Allegato.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-LIGURIA.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-VENETO.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-BOLZANO.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-CAMPANIA.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/Basilicata-Focus2022-Tavole.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-MARCHE.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-ABRUZZO.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-FVG.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/Toscana_Focus2022.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-Valle-dAosta-ValléedAoste.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-TRENTO.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/EmiliaRomagna_Focus2022_allegato.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-LAZIO.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/Umbria-Focus2022-Tavole.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-MOLISE.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/TAVOLE_STAT-CALABRIA.xlsx\n",
      "/Users/marinapavlova/Documents/digitalnomadism/popolazione2022/Piemonte_Focus-2022_Allegato.xlsx\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.getcwd()\n",
    "town_population = {}\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(file_path)\n",
    "\n",
    "        sheet = pd.read_excel(file_path, sheet_name=\"Tavola A1\")\n",
    "        sheet.columns = sheet.iloc[1]  \n",
    "        sheet = sheet[2:].reset_index(drop=True)\n",
    "\n",
    "        \n",
    "        if 'Denominazione Comune' in sheet.columns and 'Popolazione al 1° gennaio - Totale' in sheet.columns:\n",
    "            comuni = sheet['Denominazione Comune'].tolist()\n",
    "            popolazioni = sheet['Popolazione al 1° gennaio - Totale'].tolist()\n",
    "            \n",
    "            \n",
    "            for comune, popolazione in zip(comuni, popolazioni):\n",
    "                try:\n",
    "                    town_population[comune.lower()] = popolazione\n",
    "                except AttributeError:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4027aa08-2b5a-4bc1-8b7d-7b271f1d493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "['abruzzo', 'basilicata', 'bolzano', 'calabria', 'campania', 'emilia romagna', 'fvg', 'friuli venezia', 'friuli venezia giulia', 'lazio', 'liguria', 'lombardia', 'marche', 'molise', 'piemonte', 'puglia', 'sardegna', 'sicilia', 'toscana', 'trentino', 'umbria', 'valle di aosta', 'veneto']\n"
     ]
    }
   ],
   "source": [
    "regions_upper = [\"Sardegna\", \n",
    "           \"Sicilia\",\n",
    "           \"Lombardia\",\n",
    "           \"Puglia\",\n",
    "           \"Liguria\",\n",
    "           \"Veneto\",\n",
    "           \"Bolzano\",\n",
    "           \"Campania\", \n",
    "           \"Basilicata\",\n",
    "           \"Marche\",\n",
    "           \"Abruzzo\", \n",
    "           \"Friuli Venezia Giulia\", \"Friuli Venezia\", \"FVG\",\n",
    "           \"Toscana\", \n",
    "           \"Valle di Aosta\",\n",
    "           \"Trentino\",\n",
    "           \"Emilia Romagna\",\n",
    "           \"Lazio\",\n",
    "           \"Umbria\",\n",
    "           \"Molise\",\n",
    "           \"Calabria\",\n",
    "           \"Piemonte\"]\n",
    "\n",
    "print(len(regions_upper)) # 3 more bc ISTAT has separate files for Trento and Bolzano + i added other names for FVG\n",
    "\n",
    "regions_upper = sorted(regions_upper)\n",
    "regioni = [place.lower() for place in regions_upper]\n",
    "    \n",
    "print(regioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6055edf-5bc3-4060-9fce-5e41cef4c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    doc_id  sentence_id  token_id           token           lemma   pos  \\\n",
      "0  text1_1            1         2       filosofia       filosofia  NOUN   \n",
      "1  text1_1            1         3  rivoluzionaria  rivoluzionario   ADJ   \n",
      "2  text1_1            1         5         portata         portata  NOUN   \n",
      "3  text1_1            1        10           nuovo           nuovo   ADJ   \n",
      "4  text1_1            1        11            modo            modo  NOUN   \n",
      "\n",
      "   head_token_id dep_rel entity entity_type  iob  entity_count  entity_id  \\\n",
      "0              2    ROOT    NaN         NaN  NaN             1          2   \n",
      "1              2    amod    NaN         NaN  NaN             1          3   \n",
      "2              2    nmod    NaN         NaN  NaN             1          5   \n",
      "3             11    amod    NaN         NaN  NaN             1         10   \n",
      "4              2    nmod    NaN         NaN  NaN             1         11   \n",
      "\n",
      "      token_space     lemma_space    token_entity    lemma_entity  ent_root  \\\n",
      "0       filosofia       filosofia       filosofia       filosofia     False   \n",
      "1  rivoluzionaria  rivoluzionario  rivoluzionaria  rivoluzionario     False   \n",
      "2         portata         portata         portata         portata     False   \n",
      "3           nuovo           nuovo           nuovo           nuovo     False   \n",
      "4            modo            modo            modo            modo     False   \n",
      "\n",
      "  refdoc_id category  \n",
      "0     text1     None  \n",
      "1     text1     None  \n",
      "2     text1     None  \n",
      "3     text1     None  \n",
      "4     text1     None  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NLP_data_entities.csv\")\n",
    "\n",
    "def categorize_place(row):\n",
    "    regions_upper = [\"Sardegna\", \n",
    "           \"Sicilia\",\n",
    "           \"Lombardia\",\n",
    "           \"Puglia\",\n",
    "           \"Liguria\",\n",
    "           \"Veneto\",\n",
    "           \"Bolzano\",\n",
    "           \"Campania\", \n",
    "           \"Basilicata\",\n",
    "           \"Marche\",\n",
    "           \"Abruzzo\", \n",
    "           \"Friuli Venezia Giulia\", \"Friuli Venezia\", \"FVG\",\n",
    "           \"Toscana\", \n",
    "           \"Valle di Aosta\",\n",
    "           \"Trentino\",\n",
    "           \"Emilia Romagna\",\n",
    "           \"Lazio\",\n",
    "           \"Umbria\",\n",
    "           \"Molise\",\n",
    "           \"Calabria\",\n",
    "           \"Piemonte\"]\n",
    "\n",
    "    regions_upper = sorted(regions_upper)\n",
    "    regioni = [place.lower() for place in regions_upper]\n",
    "\n",
    "    refdoc_id = row[\"refdoc_id\"]\n",
    "    \n",
    "    if row[\"entity_type\"] == \"LOC\":\n",
    "        place = row[\"token_entity\"]\n",
    "        \n",
    "        if place in town_population:\n",
    "            if place not in entity_sources:\n",
    "                entity_sources[place] = []\n",
    "            entity_sources[place].append(refdoc_id)\n",
    "            return \"b\" if town_population[place] < 8500 else \"c\" # borghi vs città\n",
    "        elif place in regioni:\n",
    "            if place not in entity_sources:\n",
    "                entity_sources[place] = []\n",
    "            entity_sources[place].append(refdoc_id)\n",
    "            return \"r\" # find and categorize regions\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "entity_sources = {}\n",
    "\n",
    "df[\"category\"] = df.apply(categorize_place, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n",
    "df.to_csv(\"CATEGORIZED_NLP_data_entities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56f9a4-d4a5-4635-931f-5cb2b92728a9",
   "metadata": {},
   "source": [
    "### Save unique LOC entities into DFs and CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74ef0922-d1f5-4b3c-8ba1-886ce4ee311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities (città):\n",
      "   lemma_entity\n",
      "0         paese\n",
      "1      Brindisi\n",
      "2       Trieste\n",
      "3          Roma\n",
      "4        Milano\n",
      "..          ...\n",
      "87      Potenza\n",
      "88        Melfi\n",
      "89      Pescara\n",
      "90       trento\n",
      "91       Trento\n",
      "\n",
      "[92 rows x 1 columns]\n",
      "\n",
      "Unique small towns (comuni piccoli):\n",
      "          lemma_entity\n",
      "0              Ollolai\n",
      "1           Pitigliano\n",
      "2          Santa Fiora\n",
      "3   Sambuca di Sicilia\n",
      "4             Lavenone\n",
      "..                 ...\n",
      "88         Poggioreale\n",
      "89          Salaparuta\n",
      "90           Gibellina\n",
      "91            montagna\n",
      "92           Cellamare\n",
      "\n",
      "[93 rows x 1 columns]\n",
      "\n",
      "Unique regions:\n",
      "             lemma_entity\n",
      "0              Basilicata\n",
      "1                 Sicilia\n",
      "2                   Lazio\n",
      "3               Lombardia\n",
      "4   Friuli Venezia Giulia\n",
      "5                     Fvg\n",
      "6                Calabria\n",
      "7                  Puglia\n",
      "8                Piemonte\n",
      "9                Trentino\n",
      "10                Abruzzo\n",
      "11               Campania\n",
      "12         Emilia Romagna\n",
      "13         Friuli Venezia\n",
      "14                Liguria\n",
      "15                 Marche\n",
      "16               Sardegna\n",
      "17                Toscana\n",
      "18                 Umbria\n",
      "19                 Veneto\n"
     ]
    }
   ],
   "source": [
    "città = df[df[\"category\"] == \"c\"][[\"lemma_entity\"]].drop_duplicates().reset_index(drop=True)\n",
    "comuni_piccoli = df[df[\"category\"] == \"b\"][[\"lemma_entity\"]].drop_duplicates().reset_index(drop=True)\n",
    "regioni = df[df[\"category\"] == \"r\"][[\"lemma_entity\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "città.to_csv(\"città.csv\", index=False)\n",
    "comuni_piccoli.to_csv(\"comuni_piccoli.csv\", index=False)\n",
    "regioni.to_csv(\"regioni.csv\", index=False)\n",
    "\n",
    "print(\"Unique cities (città):\")\n",
    "print(città)\n",
    "\n",
    "print(\"\\nUnique small towns (comuni piccoli):\")\n",
    "print(comuni_piccoli)\n",
    "\n",
    "print(\"\\nUnique regions:\")\n",
    "print(regioni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e816868-c676-44fc-8c36-b33999345a17",
   "metadata": {},
   "source": [
    "I then checked the files and corrected them manually. It was enough to create the map as an intermediate result. The corrected files are uploaded on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27f4e5-e42f-4059-8967-1382eb960071",
   "metadata": {},
   "source": [
    "## Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44763981-6a1f-4533-b9a3-64fc5eba1b57",
   "metadata": {},
   "source": [
    "### 1. I add n. articles that mention each place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59fd2b87-eb93-4284-abc4-c7afd883543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only unique articles\n",
    "\n",
    "for place, sources in entity_sources.items():\n",
    "    sources = set(sources)\n",
    "    entity_sources[place] = sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdeb285a-0652-4a6b-874e-f0ba4b08a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect urls\n",
    "\n",
    "def find_urls(text_id, df):\n",
    "    result = df[df['refdoc_id'] == text_id][\"url\"].tolist()[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a51ed0b9-d251-444d-ab2b-e78ab5d59043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#collecting urls\n",
    "sample = pd.read_csv(\"final_sample.csv\")\n",
    "header = [\"luogo\", \"doc_id\", \"URL\"]\n",
    "\n",
    "with open(\"places_sources.csv\", 'w', newline='') as csvfile:\n",
    "    file = csv.writer(csvfile, delimiter=',')\n",
    "    file.writerow(header)\n",
    "\n",
    "    for place, sources in entity_sources.items():\n",
    "        for source in sources:\n",
    "            url = find_urls(source, sample)\n",
    "            row = [place.title(), source, url]\n",
    "            file.writerow(row)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4627be5-1b3a-4141-8290-a82795866f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a0ea602-195f-44ac-a244-9c990b4972a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>luogo</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paese</td>\n",
       "      <td>text53</td>\n",
       "      <td>https://www.ilsole24ore.com/art/nomadi-digital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paese</td>\n",
       "      <td>text100</td>\n",
       "      <td>https://www.tgcom24.mediaset.it/magazine/nomad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paese</td>\n",
       "      <td>text93</td>\n",
       "      <td>https://www.repubblica.it/economia/diritti-e-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paese</td>\n",
       "      <td>text50</td>\n",
       "      <td>https://www.legginotizie.com/nomadismo-digital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paese</td>\n",
       "      <td>text127</td>\n",
       "      <td>https://www.lastampa.it/economia/2023/08/17/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Melfi</td>\n",
       "      <td>text150</td>\n",
       "      <td>https://www.repubblica.it/green-and-blue/2023/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Pescara</td>\n",
       "      <td>text150</td>\n",
       "      <td>https://www.repubblica.it/green-and-blue/2023/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Pescara</td>\n",
       "      <td>text155</td>\n",
       "      <td>https://www.ilsole24ore.com/art/trento-e-pesca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Cellamare</td>\n",
       "      <td>text154</td>\n",
       "      <td>https://www.corriere.it/economia/lavoro/22_mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Trento</td>\n",
       "      <td>text155</td>\n",
       "      <td>https://www.ilsole24ore.com/art/trento-e-pesca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         luogo   doc_id                                                URL\n",
       "0        Paese   text53  https://www.ilsole24ore.com/art/nomadi-digital...\n",
       "1        Paese  text100  https://www.tgcom24.mediaset.it/magazine/nomad...\n",
       "2        Paese   text93  https://www.repubblica.it/economia/diritti-e-c...\n",
       "3        Paese   text50  https://www.legginotizie.com/nomadismo-digital...\n",
       "4        Paese  text127  https://www.lastampa.it/economia/2023/08/17/ne...\n",
       "..         ...      ...                                                ...\n",
       "489      Melfi  text150  https://www.repubblica.it/green-and-blue/2023/...\n",
       "490    Pescara  text150  https://www.repubblica.it/green-and-blue/2023/...\n",
       "491    Pescara  text155  https://www.ilsole24ore.com/art/trento-e-pesca...\n",
       "492  Cellamare  text154  https://www.corriere.it/economia/lavoro/22_mag...\n",
       "493     Trento  text155  https://www.ilsole24ore.com/art/trento-e-pesca...\n",
       "\n",
       "[494 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_sources = pd.read_csv(\"places_sources.csv\")\n",
    "places_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "254f4c47-c328-4559-bf80-dd1c67aa4329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comuni_piccoli_URLs.csv\n",
      "città_URLs.csv\n",
      "regioni_URLs.csv\n"
     ]
    }
   ],
   "source": [
    "#keeping only final places (that i corrected manually)\n",
    "\n",
    "places_sources = pd.read_csv(\"places_sources.csv\")\n",
    "places_sources['luogo'].apply(lambda x: x.title())\n",
    "\n",
    "folder_path = os.getcwd()\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('corrected.csv'):\n",
    "        list_corrected = pd.read_csv(filename)\n",
    "        list_upd = places_sources.merge(list_corrected, how=\"right\", on=\"luogo\")\n",
    "        new_file = filename.split(\"_corrected.csv\")[0] + \"_URLs.csv\"\n",
    "        list_upd.to_csv(new_file, index=False)\n",
    "        print(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef3cf5-89fe-490f-9ffb-923d7528c4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
